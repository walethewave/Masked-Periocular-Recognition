{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedUnmaskedDataset(Dataset):\n",
    "    def __init__(self, masked_dir, unmasked_dir, transform=None):\n",
    "        self.masked_dir = masked_dir\n",
    "        self.unmasked_dir = unmasked_dir\n",
    "        self.transform = transform\n",
    "        self.masked_images = os.listdir(masked_dir)\n",
    "        self.unmasked_images = os.listdir(unmasked_dir)\n",
    "        self.images = self.masked_images + self.unmasked_images\n",
    "        self.labels = [1] * len(self.masked_images) + [0] * len(self.unmasked_images)  # 1 for masked, 0 for unmasked\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.masked_images):\n",
    "            img_path = os.path.join(self.masked_dir, self.masked_images[idx])\n",
    "        else:\n",
    "            img_path = os.path.join(self.unmasked_dir, self.unmasked_images[idx - len(self.masked_images)])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize the images to 128x128\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_dir = r'C:\\Users\\USER\\OneDrive\\Desktop\\Masked Face Detection using Periocular Region\\Masked_LFW_Dataset'  # Updated path\n",
    "# unmasked_dir = r'C:\\Users\\USER\\OneDrive\\Desktop\\Masked Face Detection using Periocular Region\\LFW_without_Mask'  # Updated path\n",
    "masked_dir = os.getcwd()+\"\\\\Masked_LFW_Dataset\\\\Masked_LFW_Dataset\"\n",
    "unmasked_dir = os.getcwd()+\"\\\\LFW_without_Mask\\\\LFW_without_Mask\"\n",
    "dataset = MaskedUnmaskedDataset(masked_dir, unmasked_dir, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Continue with your training loop...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final layer to match the number of classes in  dataset (Masked and Unmasked - 2 classes)\n",
    "model.fc = torch.nn.Linear(in_features=model.fc.in_features, out_features=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Training Loop\n",
    "Here is the training loop that will run for a set number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.02333869828317245\n",
      "Epoch [2/10], Loss: 0.00013072862282203368\n",
      "Epoch [3/10], Loss: 2.610697100855985e-05\n",
      "Epoch [4/10], Loss: 1.4017465291051271e-05\n",
      "Epoch [5/10], Loss: 2.325133741428791e-05\n",
      "Epoch [6/10], Loss: 1.2494786265166084e-05\n",
      "Epoch [7/10], Loss: 7.845057712647617e-06\n",
      "Epoch [8/10], Loss: 6.376455188316424e-06\n",
      "Epoch [9/10], Loss: 1.0620361658594489e-05\n",
      "Epoch [10/10], Loss: 5.611205233391547e-06\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(data_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Loss Values\n",
    "Loss Function:\n",
    "\n",
    "The loss function measures how well the model's predictions match the true labels. Lower loss values indicate better performance.\n",
    "In your case, you're using Cross-Entropy Loss, which is appropriate for multi-class classification problems (like identifying masked vs. unmasked faces).\n",
    "Epoch Results:\n",
    "\n",
    "Epoch 1: Loss starts at approximately 0.0233. This is a relatively low value, indicating that the model is already making good predictions early on.\n",
    "Subsequent Epochs: The loss decreases rapidly over the first few epochs, indicating that the model is learning effectively. By Epoch 10, the loss is around 5.61e-06, which is extremely low.\n",
    "Convergence: The rapid drop in loss suggests that the model has quickly learned the distinctions in the dataset. After the initial epochs, the decrease in loss is very gradual, indicating that the model may be nearing convergence (i.e., it has learned most of what it can from the training data).\n",
    "Interpretation of Results\n",
    "Overfitting Concerns: Given the very low loss values, it's possible that the model might be overfitting the training data, especially if your dataset is small. Overfitting occurs when the model learns to memorize the training data instead of generalizing to unseen data. This can be a concern if you see a significant drop in performance when testing on validation or test datasets.\n",
    "\n",
    "\n",
    "\n",
    "Model Evaluation\n",
    "After training, i evaluated the model using the evaluation code you provided. This part calculates the model's accuracy on the dataset, giving insight into its performance:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 100.0%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:  # You can use a separate test loader here\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the model: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "print = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
