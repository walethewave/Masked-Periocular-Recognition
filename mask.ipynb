{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedUnmaskedDataset(Dataset):\n",
    "    def __init__(self, masked_dir, unmasked_dir, transform=None):\n",
    "        self.masked_dir = masked_dir\n",
    "        self.unmasked_dir = unmasked_dir\n",
    "        self.transform = transform\n",
    "        self.masked_images = os.listdir(masked_dir)\n",
    "        self.unmasked_images = os.listdir(unmasked_dir)\n",
    "        self.images = self.masked_images + self.unmasked_images\n",
    "        self.labels = [1] * len(self.masked_images) + [0] * len(self.unmasked_images)  # 1 for masked, 0 for unmasked\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.masked_images):\n",
    "            img_path = os.path.join(self.masked_dir, self.masked_images[idx])\n",
    "        else:\n",
    "            img_path = os.path.join(self.unmasked_dir, self.unmasked_images[idx - len(self.masked_images)])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize the images to 128x128\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_dir = r'C:\\Users\\USER\\OneDrive\\Desktop\\Masked Face Detection using Periocular Region\\Masked_LFW_Dataset'  # Updated path\n",
    "# unmasked_dir = r'C:\\Users\\USER\\OneDrive\\Desktop\\Masked Face Detection using Periocular Region\\LFW_without_Mask'  # Updated path\n",
    "masked_dir = os.getcwd()+\"\\\\Masked_LFW_Dataset\\\\Masked_LFW_Dataset\"\n",
    "unmasked_dir = os.getcwd()+\"\\\\LFW_without_Mask\\\\LFW_without_Mask\"\n",
    "dataset = MaskedUnmaskedDataset(masked_dir, unmasked_dir, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Continue with your training loop...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final layer to match the number of classes in  dataset (Masked and Unmasked - 2 classes)\n",
    "model.fc = torch.nn.Linear(in_features=model.fc.in_features, out_features=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Training Loop\n",
    "Here is the training loop that will run for a set number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.020064705423711818\n",
      "Epoch [2/10], Loss: 0.00560422752966214\n",
      "Epoch [3/10], Loss: 0.00010291419536854867\n",
      "Epoch [4/10], Loss: 2.9157192567825322e-05\n",
      "Epoch [5/10], Loss: 1.1651824673370624e-05\n",
      "Epoch [6/10], Loss: 1.0145495652026047e-05\n",
      "Epoch [7/10], Loss: 1.4162202586784722e-05\n",
      "Epoch [8/10], Loss: 1.0149122007455597e-05\n",
      "Epoch [9/10], Loss: 6.7722102936957445e-06\n",
      "Epoch [10/10], Loss: 3.6952404139518234e-06\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(data_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Loss Values\n",
    "Loss Function:\n",
    "\n",
    "The loss function measures how well the model's predictions match the true labels. Lower loss values indicate better performance.\n",
    "In your case, you're using Cross-Entropy Loss, which is appropriate for multi-class classification problems (like identifying masked vs. unmasked faces).\n",
    "Epoch Results:\n",
    "\n",
    "Epoch 1: Loss starts at approximately 0.0233. This is a relatively low value, indicating that the model is already making good predictions early on.\n",
    "Subsequent Epochs: The loss decreases rapidly over the first few epochs, indicating that the model is learning effectively. By Epoch 10, the loss is around 5.61e-06, which is extremely low.\n",
    "Convergence: The rapid drop in loss suggests that the model has quickly learned the distinctions in the dataset. After the initial epochs, the decrease in loss is very gradual, indicating that the model may be nearing convergence (i.e., it has learned most of what it can from the training data).\n",
    "Interpretation of Results\n",
    "Overfitting Concerns: Given the very low loss values, it's possible that the model might be overfitting the training data, especially if your dataset is small. Overfitting occurs when the model learns to memorize the training data instead of generalizing to unseen data. This can be a concern if you see a significant drop in performance when testing on validation or test datasets.\n",
    "\n",
    "\n",
    "\n",
    "Model Evaluation\n",
    "After training, i evaluated the model using the evaluation code you provided. This part calculates the model's accuracy on the dataset, giving insight into its performance:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 100.0%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:  # You can use a separate test loader here\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the model: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have split your dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Dataset into Training and Validation Sets:\n",
    "We'll use train_test_split from sklearn.model_selection to split the dataset into training and validation sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Get the indices for train and validation sets\n",
    "train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
    "\n",
    "# Use Subset to create new Datasets for training and validation\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "# Create DataLoaders for both datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify Training Loop to Include Validation:\n",
    "Now, we will adjust the training loop to track both training loss and validation loss after each epoch. This will help us monitor if the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print = ...\n",
    "del print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.0270\n",
      "Epoch [2/10], Train Loss: 0.0200\n",
      "Epoch [3/10], Train Loss: 0.0001\n",
      "Epoch [4/10], Train Loss: 0.0000\n",
      "Epoch [5/10], Train Loss: 0.0000\n",
      "Epoch [6/10], Train Loss: 0.0000\n",
      "Epoch [7/10], Train Loss: 0.0000\n",
      "Epoch [8/10], Train Loss: 0.0215\n",
      "Epoch [9/10], Train Loss: 0.0153\n",
      "Epoch [10/10], Train Loss: 0.0024\n",
      "Accuracy of the model: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Make sure 'print' is not overridden\n",
    "try:\n",
    "    del print\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Dataset Class\n",
    "class MaskedUnmaskedDataset(Dataset):\n",
    "    def __init__(self, masked_dir, unmasked_dir, transform=None):\n",
    "        self.masked_dir = masked_dir\n",
    "        self.unmasked_dir = unmasked_dir\n",
    "        self.transform = transform\n",
    "        self.masked_images = os.listdir(masked_dir)\n",
    "        self.unmasked_images = os.listdir(unmasked_dir)\n",
    "        self.images = self.masked_images + self.unmasked_images\n",
    "        self.labels = [1] * len(self.masked_images) + [0] * len(self.unmasked_images)  # 1 for masked, 0 for unmasked\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.masked_images):\n",
    "            img_path = os.path.join(self.masked_dir, self.masked_images[idx])\n",
    "        else:\n",
    "            img_path = os.path.join(self.unmasked_dir, self.unmasked_images[idx - len(self.masked_images)])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Image Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize the images to 128x128\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "masked_dir = os.getcwd() + \"\\\\Masked_LFW_Dataset\\\\Masked_LFW_Dataset\"\n",
    "unmasked_dir = os.getcwd() + \"\\\\LFW_without_Mask\\\\LFW_without_Mask\"\n",
    "dataset = MaskedUnmaskedDataset(masked_dir, unmasked_dir, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define CNN Model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final layer to match the number of classes (Masked and Unmasked - 2 classes)\n",
    "model.fc = torch.nn.Linear(in_features=model.fc.in_features, out_features=2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(data_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "# Model Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:  # You can use a separate test loader here\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy of the model: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for something like this:\n",
    "print = \"some string\"  # This would override the built-in print()\n",
    "\n",
    "# Rename the variable to avoid conflict:\n",
    "log_message = \"some string\"  # Corrected variable name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on Unseen Data (Test Set Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets (80% train, 20% test)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Recreate DataLoader for train dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cross-Validation (K-fold Cross Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Regularization (Dropout or L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dropout in the model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Add dropout before the fully connected layer\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.5),  # Dropout with probability of 50%\n",
    "    torch.nn.Linear(in_features=model.fc.in_features, out_features=2)  # Final layer for 2 classes\n",
    ")\n",
    "\n",
    "# Continue training as before\n",
    "#L2 Regularization (Weight Decay):\n",
    "# can add L2 regularization by passing the weight_decay parameter to  optimizer.\n",
    "\n",
    "#python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation (Improve Generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update transform to include data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(15),  # Randomly rotate the image by 15 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify Model (Try a Simpler Model)\n",
    "ResNet50 is quite powerful.  might try a simpler architecture like a smaller CNN (Convolutional Neural Network) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(32 * 32 * 32, 128)  # 128x128 input -> 32x32 after pooling twice\n",
    "        self.fc2 = torch.nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 32 * 32)  # Flatten the tensor\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and use this model instead of ResNet50\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate and Epochs (Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m val_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader)\n\u001b[0;32m     35\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch [\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m], Train Loss: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mavg_train_loss\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.4f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, Val Loss: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mavg_val_loss\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.4f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, Val Accuracy: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mval_accuracy\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.2f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Early Stopping Logic\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m avg_val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 3  # Stop after 3 epochs with no improvement\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early Stopping Logic\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize an empty list to store the predictions\n",
    "predictions = []\n",
    "image_ids = []\n",
    "\n",
    "# Loop over the test data and make predictions\n",
    "with torch.no_grad():\n",
    "    for images, ids in test_loader:  # Assuming 'ids' are your image IDs or identifiers\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get the predicted class (index of the max log-probability)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Convert predictions and IDs to CPU, if needed\n",
    "        predicted = predicted.cpu().numpy()\n",
    "        ids = ids.cpu().numpy()\n",
    "\n",
    "        # Append predictions and ids to the list\n",
    "        predictions.extend(predicted)\n",
    "        image_ids.extend(ids)\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "df_predictions = pd.DataFrame({\n",
    "    'Image_ID': image_ids,  # Replace 'Image_ID' with the actual identifier\n",
    "    'Predicted_Class': predictions\n",
    "})\n",
    "\n",
    "# Save the predictions as a CSV file\n",
    "df_predictions.to_csv('model_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'model_predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model parameters (state dict)\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print(\"Model saved as 'model.pth'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showcase Full Advanced Deep Learning Proficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Use your dataset directories\n",
    "masked_dir = os.getcwd()+\"\\\\Masked_LFW_Dataset\\\\Masked_LFW_Dataset\"\n",
    "unmasked_dir = os.getcwd()+\"\\\\LFW_without_Mask\\\\LFW_without_Mask\"\n",
    "\n",
    "# 1. Define transformations for both training and testing sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. Load datasets using ImageFolder (assuming a folder structure like masked_dir/class1/, unmasked_dir/class2/)\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=masked_dir, transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=unmasked_dir, transform=transform)\n",
    "\n",
    "# 3. Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 4. Load a Pretrained Model (ResNet50) and modify the final layer for binary classification (masked/unmasked)\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze the layers except the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final fully connected layer\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(model.fc.in_features, 2)  # For binary classification\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 5. Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# 6. Training loop with validation\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "# 7. Plot the training and validation loss curves\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 8. Making Predictions and Saving to CSV\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "image_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ids in test_loader:  # Assuming 'ids' are your image identifiers\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.cpu().numpy()\n",
    "        ids = ids.cpu().numpy()  # Assuming image IDs are passed\n",
    "\n",
    "        predictions.extend(predicted)\n",
    "        image_ids.extend(ids)\n",
    "\n",
    "# Save predictions to CSV\n",
    "df_predictions = pd.DataFrame({\n",
    "    'Image_ID': image_ids,  # Replace 'Image_ID' with actual identifier if needed\n",
    "    'Predicted_Class': predictions\n",
    "})\n",
    "\n",
    "df_predictions.to_csv('model_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'model_predictions.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
